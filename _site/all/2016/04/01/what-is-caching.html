<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>What is caching?</title>
  <meta name="description" content="There are many different definitions of caching, depending on contexts. Caching is ubiquitous as long as locality is present – from CPU to CDN, from hardware...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://pelikan.io/all/2016/04/01/what-is-caching.html">
  <link rel="alternate" type="application/rss+xml" title="Pelikan Cache" href="http://pelikan.io/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Pelikan Cache</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/blog/">Blog</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/project/">Project</a>
          
        
          
          <a class="page-link" href="/resources/">Resources</a>
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">What is caching?</h1>
    <p class="post-meta"><time datetime="2016-04-01T11:11:11-07:00" itemprop="datePublished">Apr 1, 2016</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name"><a href="https://twitter.com/thinkingfish">Yao Yue</a></span></span></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>There are many different definitions of caching, depending on contexts. Caching is ubiquitous as long as locality is present – from CPU to CDN, from hardware controllers to Wide Area Networks. Caching also varies greatly in its medium and location, and as a result, its speed. CPU cache using SRAM clocks a mere couple of nanoseconds per operation, while downloading an image from the nearest CDN server can take seconds. But there is one invariant – people use cache as a way to get data faster and more cheaply.</p>

<p>The lifeline of caching is <strong>performance</strong>, the one property that justifies its existence. People routinely tolerate slightly incorrect data in exchange of getting <em>some</em> version of that quickly. Because of its economy, caching is also often the answer to scalability – intended as an optimization, plenty of services will simply stop working if their cache suddenly disappears.</p>

<p>A little paranoia about things that may slow down caching is thus understandable, once you realize the whole existence, a.k.a. competitive advantage, of caching systems lie squarely on it.</p>

<h2 id="caching-in-a-datacenter">Caching in a Datacenter</h2>

<p>Caching in datacenters is the focus here (this will be what we mean by ‘caching’ unless otherwise specified). Making cache worthwhile in datacenters means finding the fastest, cheapest way to data. To achieve so, one needs to understand both the underlying infrastructure and the problem.</p>

<h3 id="the-infrastructure">The Infrastructure</h3>

<p>Datacenters are filled with servers and networks that are largely homogeneous, especially compared to the broader Internet. Caching in a datacenter should take into account this particular reality – the physics of networking fabrics and the software that send, forward and receive data. If it takes about 100μs to send a byte from end to end, a request will take at least 200μs to receive a response. If the kernel network stack takes 15μs to process a TCP packet, any request over TCP will have to pay that overhead on both ends. Caching has to abide by the rule of the infrastructure, and chooses topological placement and storage medium accordingly.</p>

<p>Most datacenters are still using Ethernet. Current network bandwidth ranges from 1Gbps to 40Gbps at the edge, with 10Gbps increasingly becoming mainstream. In such a setup, the end-to-end latencies are often on the order of 100μs. SSDs have a seek time at about the same level, with a bandwidth somewhere between 100MB/s and 1GB/s, also comparable to Ethernet. Spinning disks, on the other hand, have a seek time one to two orders of magnitude higher, and are thus much slow for random read/write. DRAM bandwidths are on the order of 10GB/s, with an access latency of about 100ns.</p>

<p>The following figure captures the relative “closeness” of different data locations.
  <img src="/assets/img/data_access_speed.jpg" alt="data access speed" /></p>

<p>The typical datacenter infrastructure implies a few things:</p>

<ol>
  <li>Local memory access is significantly faster than remote memory access, it also offers much higher throughput.</li>
  <li>SSD and Ethernet are comparable both in terms of latency and throughput, depending on the specific products and setup. Thus a choice between the two is not always obvious. However, getting data remotely opens the door to scaling out, as the data set can now be distributed. This explains the dominance of distributed in-memory store over SSD as cache.</li>
  <li>Getting data stored remotely on SSD is usually slower than remote data in memory, but still on the same order of magnitude. For larger objects, transfer latencies increasingly dominate performance, rendering the difference insignificant.</li>
  <li>Faster communication and/or local storage medium can be game-changers. For example, infiniband lowers the end-to-end latency by two orders of magnitude, so any systems that builds on top of it must re-evaluate the relationship between local and remote data access. If non-volatile memory becomes a reality in the next few years, it will blur the performance boundary between volatile and persistent storage, forcing architects to rethink their storage hierarchy.</li>
</ol>

<h3 id="the-problem">The Problem</h3>

<p>Caching in datacenters means getting data from a location other than the canonical source, e.g. from a database or a series of computation steps. At its core are two functionalities:</p>

<ul>
  <li>storing data</li>
  <li>accessing data</li>
</ul>

<p>To get the performance edge, cached data is overwhelmingly stored in memory. However, as the infrastructure indicates, SSD (and NVRAM in the future) should be considered when the right conditions are met. From a resource point of view, any caching solution must also have good control of data layout and resource footprint, to achieve good storage efficiency.</p>

<p>There are a great deal to consider when it comes to data access. The most important difference is whether the network is involved, meaning local versus remote. One can also directly access local data if it happens to be in the same address space. This gives us several “modes” of caching.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Mode</th>
      <th style="text-align: center">Over Network?</th>
      <th style="text-align: center">Comm Protocol?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">in-process</td>
      <td style="text-align: center">No</td>
      <td style="text-align: center">No</td>
    </tr>
    <tr>
      <td style="text-align: left">local</td>
      <td style="text-align: center">No</td>
      <td style="text-align: center">Yes</td>
    </tr>
    <tr>
      <td style="text-align: left">remote</td>
      <td style="text-align: center">Yes</td>
      <td style="text-align: center">Yes</td>
    </tr>
  </tbody>
</table>

<p>On top of that, there are an array of communication options, each presenting different performance characteristics. For example, UDP generally boasts lower overhead than TCP. When the data is stored locally, one can choose to use Unix domain socket, pipes or messaging over shared memory, which are considered lighter-weight compared to their networking counterparts.</p>

<h3 id="requirements">Requirements</h3>

<p>Marrying the problem at hand with underlying constraints, caching in datacenter is usually a combination of in-process caching, local- and remote- in-memory caching. There are a few commonalities among good caching solutions:</p>

<ul>
  <li>deliver latency and throughput that are close to the limits of bare-metal and operating systems</li>
  <li>often use the most lightweight protocol available for the scenario</li>
  <li>store most data in memory, using persistent storage as an extension</li>
  <li>directly manage memory and use data structures that are memory-efficient</li>
</ul>

<h3 id="hidden-requirements"><em>Hidden</em> Requirements</h3>

<p>Until now, we have completely ignored the operational aspect of caching. But operations is arguably the biggest hidden assumption about most systems running in datacenters – it has to be a production-ready system.</p>

<p>The exact definition of <a href="http://programmers.stackexchange.com/questions/61726/define-production-ready">production readiness</a> is still an open question. In a gist, a production-ready system is an operations-friendly system, which offers:</p>

<ul>
  <li>customization and optimization through configuration</li>
  <li>the ability to log meaningful events for monitoring and debugging</li>
  <li>statistics that reflect the state of the service</li>
  <li>stability and predictability in runtime characteristics, preferably at various scales</li>
  <li>on-going maintainability and room for new features</li>
</ul>

<p>One may notice that the requirement list for production-readiness is even longer than the one for basic functionality! Furthermore, some of them, such as logging, may stand in the way of achieving some other goal, such as delivering optimal throughput and latency.</p>

<p>Balancing goals at odds with each other and weighing all the options remain the main challenge facing anybody who wants to build a good caching solution.</p>

<h2 id="coming-up">Coming up…</h2>

<p>In the next post, we will explore some design principles that allows us to satisfy both the obvious and hidden requirements.</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Pelikan Cache</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>mailing list:</li>
          <li><a href="mailto:pelikan-cache@googlegroups.com">pelikan-cache@googlegroups.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/twitter"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">twitter</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/pelikan_cache"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">pelikan_cache</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Pelikan is a framework for building cache services. It is part of Twitter's unified cache project.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
